{
  "generation_stats": [
    {
      "generation": 0,
      "population_size": 10,
      "avg_fitness": 0.291,
      "best_fitness": 0.438,
      "worst_fitness": 0.13199999999999998,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.485,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "analogical",
      "dominant_memory": "recency",
      "elapsed_seconds": 13.228638887405396
    },
    {
      "generation": 1,
      "population_size": 10,
      "avg_fitness": 0.41459999999999997,
      "best_fitness": 0.45599999999999996,
      "worst_fitness": 0.378,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.6910000000000001,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "chain-of-thought",
      "dominant_memory": "success-rate",
      "elapsed_seconds": 12.99497103691101
    },
    {
      "generation": 2,
      "population_size": 10,
      "avg_fitness": 0.44580000000000003,
      "best_fitness": 0.46799999999999997,
      "worst_fitness": 0.432,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.743,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "chain-of-thought",
      "dominant_memory": "relevance",
      "elapsed_seconds": 12.857404947280884
    },
    {
      "generation": 3,
      "population_size": 10,
      "avg_fitness": 0.4548,
      "best_fitness": 0.46799999999999997,
      "worst_fitness": 0.414,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.758,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "chain-of-thought",
      "dominant_memory": "relevance",
      "elapsed_seconds": 12.673970937728882
    },
    {
      "generation": 4,
      "population_size": 10,
      "avg_fitness": 0.4662,
      "best_fitness": 0.48,
      "worst_fitness": 0.42,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.777,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "analogical",
      "dominant_memory": "recency",
      "elapsed_seconds": 12.92330288887024
    },
    {
      "generation": 5,
      "population_size": 10,
      "avg_fitness": 0.4728,
      "best_fitness": 0.48,
      "worst_fitness": 0.426,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.788,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "step-by-step",
      "dominant_memory": "recency",
      "elapsed_seconds": 12.768318176269531
    },
    {
      "generation": 6,
      "population_size": 10,
      "avg_fitness": 0.48,
      "best_fitness": 0.48,
      "worst_fitness": 0.48,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.8,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "step-by-step",
      "dominant_memory": "relevance",
      "elapsed_seconds": 12.808329105377197
    },
    {
      "generation": 7,
      "population_size": 10,
      "avg_fitness": 0.4758,
      "best_fitness": 0.48,
      "worst_fitness": 0.438,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.793,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "analogical",
      "dominant_memory": "relevance",
      "elapsed_seconds": 12.664678812026978
    },
    {
      "generation": 8,
      "population_size": 10,
      "avg_fitness": 0.4704,
      "best_fitness": 0.48,
      "worst_fitness": 0.426,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.784,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "step-by-step",
      "dominant_memory": "recency",
      "elapsed_seconds": 12.718385934829712
    },
    {
      "generation": 9,
      "population_size": 10,
      "avg_fitness": 0.48,
      "best_fitness": 0.48,
      "worst_fitness": 0.48,
      "avg_raw_calibration": 0.5,
      "avg_prediction_accuracy": 0.8,
      "avg_task_accuracy": 0.0,
      "dominant_reasoning": "analogical",
      "dominant_memory": "recency",
      "elapsed_seconds": 12.870728015899658
    }
  ],
  "all_genomes": [
    {
      "genome_id": "0324bd67",
      "system_prompt": "You are a calibrated predictor who honestly assesses uncertainty.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": 0.28,
      "risk_tolerance": 0.12,
      "temperature": 0.63,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "56af47cb",
      "system_prompt": "You think probabilistically, always estimating likelihoods.",
      "reasoning_style": "first-principles",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": 0.07,
      "risk_tolerance": 0.51,
      "temperature": 1.07,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "4204c72d",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 10,
      "memory_weighting": "recency",
      "confidence_bias": -0.18,
      "risk_tolerance": 0.8,
      "temperature": 0.62,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "ba08f9f0",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "elimination",
      "memory_window": 4,
      "memory_weighting": "success-rate",
      "confidence_bias": 0.06,
      "risk_tolerance": 0.57,
      "temperature": 0.6,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "24894e09",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.17,
      "risk_tolerance": 0.55,
      "temperature": 0.5,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "321bdcd4",
      "system_prompt": "You are a devil's advocate who stress-tests your own reasoning.",
      "reasoning_style": "first-principles",
      "memory_window": 8,
      "memory_weighting": "success-rate",
      "confidence_bias": 0.06,
      "risk_tolerance": 0.62,
      "temperature": 1.02,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "cf4b0b01",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 6,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.49,
      "temperature": 0.68,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "ffbf2a49",
      "system_prompt": "You are a devil's advocate who stress-tests your own reasoning.",
      "reasoning_style": "elimination",
      "memory_window": 1,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.04,
      "risk_tolerance": 0.24,
      "temperature": 0.87,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "1b32902d",
      "system_prompt": "You are a pattern-matcher who looks for structural similarity.",
      "reasoning_style": "debate-self",
      "memory_window": 5,
      "memory_weighting": "recency",
      "confidence_bias": 0.13,
      "risk_tolerance": 0.41,
      "temperature": 0.42,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "fc7e9982",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": 0.17,
      "risk_tolerance": 0.27,
      "temperature": 0.46,
      "generation": 0,
      "parent_ids": [],
      "fitness_history": []
    },
    {
      "genome_id": "d28be068",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 6,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.49,
      "temperature": 0.68,
      "generation": 1,
      "parent_ids": [
        "cf4b0b01"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "581c57aa",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 10,
      "memory_weighting": "recency",
      "confidence_bias": -0.18,
      "risk_tolerance": 0.8,
      "temperature": 0.62,
      "generation": 1,
      "parent_ids": [
        "4204c72d"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "a85ec1a1",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "first-principles",
      "memory_window": 4,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.18,
      "risk_tolerance": 0.8,
      "temperature": 0.62,
      "generation": 1,
      "parent_ids": [
        "cf4b0b01",
        "4204c72d"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4f2cfc3e",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.55,
      "temperature": 0.68,
      "generation": 1,
      "parent_ids": [
        "24894e09",
        "cf4b0b01"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "73d3cab8",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "debate-self",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.18,
      "risk_tolerance": 0.8,
      "temperature": 0.5,
      "generation": 1,
      "parent_ids": [
        "4204c72d",
        "24894e09"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "2fe4274b",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.17,
      "risk_tolerance": 0.36,
      "temperature": 0.5,
      "generation": 1,
      "parent_ids": [
        "24894e09",
        "cf4b0b01"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4c9d0b7d",
      "system_prompt": "You are a devil's advocate who stress-tests your own reasoning.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 6,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 1,
      "parent_ids": [
        "cf4b0b01",
        "4204c72d"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "b4c0369e",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 10,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.13,
      "risk_tolerance": 0.49,
      "temperature": 0.78,
      "generation": 1,
      "parent_ids": [
        "4204c72d",
        "cf4b0b01"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "29951ec3",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 10,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.18,
      "risk_tolerance": 0.61,
      "temperature": 0.62,
      "generation": 1,
      "parent_ids": [
        "4204c72d",
        "cf4b0b01"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "89a84f0e",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 9,
      "memory_weighting": "recency",
      "confidence_bias": -0.17,
      "risk_tolerance": 0.88,
      "temperature": 0.62,
      "generation": 1,
      "parent_ids": [
        "24894e09",
        "4204c72d"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "10eef088",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.55,
      "temperature": 0.68,
      "generation": 2,
      "parent_ids": [
        "4f2cfc3e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "8b955212",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 6,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.49,
      "temperature": 0.68,
      "generation": 2,
      "parent_ids": [
        "d28be068"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "172882f0",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 5,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 2,
      "parent_ids": [
        "4c9d0b7d",
        "4f2cfc3e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "ca9311df",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 6,
      "memory_weighting": "relevance",
      "confidence_bias": -0.22,
      "risk_tolerance": 0.72,
      "temperature": 0.71,
      "generation": 2,
      "parent_ids": [
        "4c9d0b7d",
        "4f2cfc3e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "85dca0f9",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "debate-self",
      "memory_window": 6,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.55,
      "temperature": 0.77,
      "generation": 2,
      "parent_ids": [
        "4f2cfc3e",
        "d28be068"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "20937c46",
      "system_prompt": "You are a devil's advocate who stress-tests your own reasoning.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 2,
      "parent_ids": [
        "4c9d0b7d",
        "d28be068"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4a12a2e9",
      "system_prompt": "You are a devil's advocate who stress-tests your own reasoning.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 7,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 2,
      "parent_ids": [
        "4c9d0b7d",
        "d28be068"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "e0e6122c",
      "system_prompt": "You break every problem down to its fundamental principles.",
      "reasoning_style": "first-principles",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.82,
      "temperature": 0.68,
      "generation": 2,
      "parent_ids": [
        "4c9d0b7d",
        "4f2cfc3e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "155ac9dd",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.73,
      "generation": 2,
      "parent_ids": [
        "4c9d0b7d",
        "4f2cfc3e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "38334c7a",
      "system_prompt": "You are a devil's advocate who stress-tests your own reasoning.",
      "reasoning_style": "elimination",
      "memory_window": 6,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.55,
      "temperature": 0.69,
      "generation": 2,
      "parent_ids": [
        "4f2cfc3e",
        "4c9d0b7d"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5c709e33",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.73,
      "generation": 3,
      "parent_ids": [
        "155ac9dd"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "3ff1d685",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.55,
      "temperature": 0.68,
      "generation": 3,
      "parent_ids": [
        "10eef088"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "fb90d55b",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 5,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.55,
      "temperature": 0.68,
      "generation": 3,
      "parent_ids": [
        "10eef088",
        "172882f0"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "d9e8c0b8",
      "system_prompt": "You think probabilistically, always estimating likelihoods.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.55,
      "temperature": 0.58,
      "generation": 3,
      "parent_ids": [
        "10eef088",
        "155ac9dd"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "6f1ba10f",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.69,
      "generation": 3,
      "parent_ids": [
        "172882f0",
        "155ac9dd"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "22b501ef",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.19,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 3,
      "parent_ids": [
        "172882f0",
        "10eef088"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "068563fa",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 6,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.69,
      "temperature": 0.69,
      "generation": 3,
      "parent_ids": [
        "172882f0",
        "10eef088"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "affc3cb8",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.71,
      "temperature": 0.69,
      "generation": 3,
      "parent_ids": [
        "155ac9dd",
        "172882f0"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "2f19522a",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.27,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 3,
      "parent_ids": [
        "172882f0",
        "10eef088"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5b4f9d68",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 5,
      "memory_weighting": "relevance",
      "confidence_bias": -0.26,
      "risk_tolerance": 0.72,
      "temperature": 0.56,
      "generation": 3,
      "parent_ids": [
        "172882f0",
        "10eef088"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "8b159f4c",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.73,
      "generation": 4,
      "parent_ids": [
        "5c709e33"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "c4d61a30",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.69,
      "generation": 4,
      "parent_ids": [
        "6f1ba10f"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "b7f2f2c0",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "analogical",
      "memory_window": 6,
      "memory_weighting": "recency",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.73,
      "generation": 4,
      "parent_ids": [
        "5c709e33",
        "2f19522a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "09e404d0",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.65,
      "temperature": 0.68,
      "generation": 4,
      "parent_ids": [
        "6f1ba10f",
        "2f19522a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f00e59f0",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 4,
      "parent_ids": [
        "2f19522a",
        "5c709e33"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f6ce44b6",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.28,
      "risk_tolerance": 0.55,
      "temperature": 0.64,
      "generation": 4,
      "parent_ids": [
        "5c709e33",
        "6f1ba10f"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "668ced66",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.27,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 4,
      "parent_ids": [
        "5c709e33",
        "2f19522a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "78daa68b",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 4,
      "parent_ids": [
        "6f1ba10f",
        "2f19522a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5b976fb2",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 4,
      "parent_ids": [
        "5c709e33",
        "2f19522a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "8bf176f2",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.2,
      "risk_tolerance": 0.55,
      "temperature": 0.73,
      "generation": 4,
      "parent_ids": [
        "6f1ba10f",
        "5c709e33"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "7d9c8f7f",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "f00e59f0"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5e25b045",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 5,
      "parent_ids": [
        "78daa68b"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "0531828a",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.83,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "78daa68b",
        "5b976fb2"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "9f3b440f",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.21,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "5b976fb2",
        "78daa68b"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "48d69903",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "elimination",
      "memory_window": 5,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "5b976fb2",
        "f00e59f0"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f6a3d2af",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.78,
      "temperature": 0.74,
      "generation": 5,
      "parent_ids": [
        "78daa68b",
        "f00e59f0"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "2e722f07",
      "system_prompt": "You are a bold, intuitive reasoner who trusts your first instinct.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.27,
      "risk_tolerance": 0.72,
      "temperature": 0.79,
      "generation": 5,
      "parent_ids": [
        "5b976fb2",
        "f00e59f0"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "158ee271",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "f00e59f0",
        "5b976fb2"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5d246399",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "f00e59f0",
        "5b976fb2"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "8688cbc4",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.61,
      "temperature": 0.68,
      "generation": 5,
      "parent_ids": [
        "f00e59f0",
        "5b976fb2"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "612999b7",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 6,
      "parent_ids": [
        "7d9c8f7f"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "6a2edc1a",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 6,
      "parent_ids": [
        "5e25b045"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f6557ff1",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.82,
      "generation": 6,
      "parent_ids": [
        "5e25b045",
        "0531828a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "3cc7f75a",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.55,
      "generation": 6,
      "parent_ids": [
        "5e25b045",
        "7d9c8f7f"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "91da42ee",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 6,
      "parent_ids": [
        "5e25b045",
        "7d9c8f7f"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "20ca5b93",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 6,
      "parent_ids": [
        "5e25b045",
        "0531828a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "2d20a6e2",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "first-principles",
      "memory_window": 7,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.57,
      "generation": 6,
      "parent_ids": [
        "5e25b045",
        "7d9c8f7f"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "0963361e",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "elimination",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 6,
      "parent_ids": [
        "0531828a",
        "5e25b045"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5811e75d",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "first-principles",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.87,
      "temperature": 0.68,
      "generation": 6,
      "parent_ids": [
        "0531828a",
        "5e25b045"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "70cb9bba",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.83,
      "temperature": 0.68,
      "generation": 6,
      "parent_ids": [
        "7d9c8f7f",
        "0531828a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "5c25d974",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 7,
      "parent_ids": [
        "612999b7"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "e012c0fd",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 7,
      "parent_ids": [
        "6a2edc1a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "b968cad8",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 7,
      "parent_ids": [
        "6a2edc1a",
        "612999b7"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "ae5acc33",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.75,
      "generation": 7,
      "parent_ids": [
        "6a2edc1a",
        "f6557ff1"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "8703f914",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 7,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.73,
      "temperature": 0.82,
      "generation": 7,
      "parent_ids": [
        "f6557ff1",
        "612999b7"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "b8a3ea37",
      "system_prompt": "You think probabilistically, always estimating likelihoods.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.63,
      "generation": 7,
      "parent_ids": [
        "6a2edc1a",
        "f6557ff1"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "9d14350c",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.83,
      "temperature": 0.69,
      "generation": 7,
      "parent_ids": [
        "612999b7",
        "6a2edc1a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4a35005d",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 7,
      "parent_ids": [
        "f6557ff1",
        "6a2edc1a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "95c5f849",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.7,
      "generation": 7,
      "parent_ids": [
        "6a2edc1a",
        "f6557ff1"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "9331bffb",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.82,
      "generation": 7,
      "parent_ids": [
        "f6557ff1",
        "6a2edc1a"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4f909b51",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 8,
      "parent_ids": [
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4b41f365",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 8,
      "parent_ids": [
        "e012c0fd"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "d0dc417e",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.69,
      "generation": 8,
      "parent_ids": [
        "e012c0fd",
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "6094cf9c",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.69,
      "generation": 8,
      "parent_ids": [
        "e012c0fd",
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "cf6cad4c",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 8,
      "parent_ids": [
        "e012c0fd",
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "8a16ab5f",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.21,
      "risk_tolerance": 0.77,
      "temperature": 0.69,
      "generation": 8,
      "parent_ids": [
        "e012c0fd",
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f22ff570",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "chain-of-thought",
      "memory_window": 9,
      "memory_weighting": "recency",
      "confidence_bias": -0.23,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 8,
      "parent_ids": [
        "b968cad8",
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "0ce5ed84",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 8,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.53,
      "generation": 8,
      "parent_ids": [
        "b968cad8",
        "5c25d974"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "1242a1a9",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "debate-self",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 8,
      "parent_ids": [
        "e012c0fd",
        "b968cad8"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "4936dd2c",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 8,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 8,
      "parent_ids": [
        "b968cad8",
        "e012c0fd"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f7cabc82",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.68,
      "generation": 9,
      "parent_ids": [
        "4f909b51"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "0a3d6b9b",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.69,
      "generation": 9,
      "parent_ids": [
        "4b41f365"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "6076a6b8",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.74,
      "generation": 9,
      "parent_ids": [
        "d0dc417e",
        "4b41f365"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "a2955b3f",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.73,
      "generation": 9,
      "parent_ids": [
        "4f909b51",
        "d0dc417e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "eba88e2c",
      "system_prompt": "You reason by eliminating wrong answers first.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.69,
      "generation": 9,
      "parent_ids": [
        "d0dc417e",
        "4b41f365"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "28655fe1",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 8,
      "memory_weighting": "success-rate",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.72,
      "temperature": 0.68,
      "generation": 9,
      "parent_ids": [
        "4f909b51",
        "4b41f365"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "f1602a9d",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.85,
      "temperature": 0.61,
      "generation": 9,
      "parent_ids": [
        "4b41f365",
        "d0dc417e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "a69f7cad",
      "system_prompt": "You break every problem down to its fundamental principles.",
      "reasoning_style": "first-principles",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.67,
      "temperature": 0.69,
      "generation": 9,
      "parent_ids": [
        "4f909b51",
        "4b41f365"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "019653ef",
      "system_prompt": "You are a careful, methodical thinker who checks each step.",
      "reasoning_style": "step-by-step",
      "memory_window": 7,
      "memory_weighting": "recency",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.78,
      "generation": 9,
      "parent_ids": [
        "4f909b51",
        "d0dc417e"
      ],
      "fitness_history": []
    },
    {
      "genome_id": "b883293a",
      "system_prompt": "You think by analogy \u2014 relate new problems to ones you know.",
      "reasoning_style": "analogical",
      "memory_window": 7,
      "memory_weighting": "relevance",
      "confidence_bias": -0.3,
      "risk_tolerance": 0.77,
      "temperature": 0.7,
      "generation": 9,
      "parent_ids": [
        "4b41f365",
        "d0dc417e"
      ],
      "fitness_history": []
    }
  ],
  "all_results": [
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "0324bd67",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.21999999999999997,
      "fitness": 0.13199999999999998
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "56af47cb",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.42999999999999994,
      "fitness": 0.25799999999999995
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "4204c72d",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "ba08f9f0",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "24894e09",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "321bdcd4",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.43999999999999995,
      "fitness": 0.26399999999999996
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "cf4b0b01",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "ffbf2a49",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.54,
      "fitness": 0.324
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "1b32902d",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.37,
      "fitness": 0.222
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 0,
      "genome_id": "fc7e9982",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.32999999999999996,
      "fitness": 0.19799999999999998
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "d28be068",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "581c57aa",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "a85ec1a1",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "4f2cfc3e",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "73d3cab8",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "2fe4274b",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "4c9d0b7d",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "b4c0369e",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.63,
      "fitness": 0.378
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "29951ec3",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.6799999999999999,
      "fitness": 0.408
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 1,
      "genome_id": "89a84f0e",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.67,
      "fitness": 0.402
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "10eef088",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "8b955212",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "172882f0",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "ca9311df",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.72,
      "fitness": 0.432
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "85dca0f9",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "20937c46",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "4a12a2e9",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "e0e6122c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "155ac9dd",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 2,
      "genome_id": "38334c7a",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "5c709e33",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "3ff1d685",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "fb90d55b",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "d9e8c0b8",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "6f1ba10f",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "22b501ef",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.69,
      "fitness": 0.414
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "068563fa",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "affc3cb8",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "2f19522a",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 3,
      "genome_id": "5b4f9d68",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.76,
      "fitness": 0.45599999999999996
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "8b159f4c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "c4d61a30",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "b7f2f2c0",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "09e404d0",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f00e59f0",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "f6ce44b6",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.78,
      "fitness": 0.46799999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "668ced66",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "78daa68b",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "5b976fb2",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 4,
      "genome_id": "8bf176f2",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.7,
      "fitness": 0.42
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "7d9c8f7f",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5e25b045",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "0531828a",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "9f3b440f",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "48d69903",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "f6a3d2af",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "2e722f07",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.77,
      "fitness": 0.46199999999999997
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "158ee271",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "5d246399",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 5,
      "genome_id": "8688cbc4",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "612999b7",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "6a2edc1a",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "f6557ff1",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "3cc7f75a",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "91da42ee",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "20ca5b93",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "2d20a6e2",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "0963361e",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "5811e75d",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 6,
      "genome_id": "70cb9bba",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "5c25d974",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "e012c0fd",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b968cad8",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "ae5acc33",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "8703f914",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "b8a3ea37",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9d14350c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "4a35005d",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "95c5f849",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 7,
      "genome_id": "9331bffb",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4f909b51",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4b41f365",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "d0dc417e",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "6094cf9c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "cf6cad4c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "8a16ab5f",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.71,
      "fitness": 0.426
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "f22ff570",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.73,
      "fitness": 0.438
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "0ce5ed84",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "1242a1a9",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 8,
      "genome_id": "4936dd2c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f7cabc82",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "0a3d6b9b",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "6076a6b8",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a2955b3f",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "eba88e2c",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "28655fe1",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "f1602a9d",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "a69f7cad",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "019653ef",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "r09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5:00 PM",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "r11",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "2",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "r02",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "5",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "e10",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "10000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "t08",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Q",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "t13",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "Human",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "t09",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "1978",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    },
    {
      "generation": 9,
      "genome_id": "b883293a",
      "task_id": "e05",
      "predicted_confidence": 0.5,
      "predicted_answer": "unknown",
      "ground_truth": "19000",
      "is_correct": false,
      "raw_calibration": 0.5,
      "prediction_accuracy": 0.8,
      "fitness": 0.48
    }
  ],
  "test_results": {
    "n_tasks": 9,
    "n_agents": 10,
    "avg_raw_calibration": 0.5,
    "avg_prediction_accuracy": 0.8,
    "avg_task_accuracy": 0.0,
    "best_fitness": 0.48000000000000004,
    "avg_fitness": 0.4800000000000001
  }
}